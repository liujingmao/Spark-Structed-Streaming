核心术语

Broker：其实就是一台Kafka服务器节点
	负责消息/数据读写请求、存储信息
	Kafka Cluster其实里面是由多个broker构成

Topic：主题
	可以根据业务将不同的数据存放在不同的主题
	日志数据==>log topic
	交易数据==> tran topic
	不同类别的消息存放在不同的topic里面  更清晰、更方便下游的数据处理

Partition：分区
	一个主题可以分为多个partition
	后期可以进行分区的扩展
	一个topic的多个分区的数据是分布式存储在多个broker上的
	每个分区内部是有序的，但是一个topic(多个partition)不一定有序的
	一个partition对应一个broker，一个broker可以管理多个partition
	每一个partition都可以设置副本系数，创建topic时可以指定副本系数


Producer：消息生产者
	就是向Kafka Broker发消息的客户端
	可以指定消息按照某个规则发送到topic指定的分区中去

Consumer：消息的消费者
	向Kafka Broker取消息的客户端
	每个消费者都要维护自己读取数据的offset/偏移量
	每个消费者都有自己的消费者组group
	同一个消费者组中的消费者消费同一个topic时，每个topic中相同的只会被消费一次
	不同消费者组消费同一个topic互不影响


Kafka数据/文件存储是什么样的

1)在Kafka文件存储时，同一个topic下有多个不同的partition
每个partition都是一个文件夹/目录
partition的命名规则：topic的名称-序号 (my-replicated-topic-0)
第一个partition序号就是0
序号最大值应该是partition数量-1

2)每个partition相当于是一个非常大的文件分配到segment文件中
segment file
 由两个部分组成：index file、data/log file

segment命名规则
partition全局的第一个segment从0开始
后续的每个segment文件名为上一个segment文件最后一条消息的offset值

offset=368776的消息/数据是什么？











Kakfa server.properties
	zookeeper.connect=hadoop000:2181
	log.dirs=/home/hadoop/app/tmp/kafka-logs
	broker.id=0

$KAFKA_HOME
bin/kafka-server-start.sh -daemon config/server.properties


kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties


kafka-topics.sh --create --bootstrap-server hadoop000:9092 --replication-factor 1 --partitions 1 --topic test
kafka-topics.sh --list --bootstrap-server hadoop000:9092

kafka-console-producer.sh --bootstrap-server hadoop000:9092 --topic test

kafka-console-consumer.sh --bootstrap-server hadoop000:9092 --topic test --from-beginning


kafka-server-start.sh -daemon $KAFKA_HOME/config/server-0.properties
kafka-server-start.sh -daemon $KAFKA_HOME/config/server-1.properties
kafka-server-start.sh -daemon $KAFKA_HOME/config/server-2.properties

kafka-topics.sh --create --bootstrap-server hadoop000:9092,hadoop000:9093,hadoop000:9094 --replication-factor 3 --partitions 1 --topic access-topic-prod

kafka-topics.sh --describe --bootstrap-server hadoop000:9092,hadoop000:9093,hadoop000:9094 --topic my-replicated-topic
kafka-console-producer.sh --bootstrap-server hadoop000:9092,hadoop000:9093,hadoop000:9094 --topic my-replicated-topic
kafka-console-consumer.sh --bootstrap-server hadoop000:9092,hadoop000:9093,hadoop000:9094 --topic access-topic-prod


flume-ng agent \
--name a1 \
--conf $FLUME_HOME/conf \
--conf-file $FLUME_HOME/config/access-kafka.conf \
-Dflume.root.logger=INFO,console





谈谈Kafka中acks参数的看法
1) 如何保证宕机时数据不丢失
	topic：partition(负责存储topic中的一部分数据)
	Cluster/Brokers：每个broker上存储一些partition
2) 多副本冗余
	一个partition可以有多个副本
	leader follower
3）多副本如何进行数据同步
	leader：对外提供读写服务的
	producer往一个partition中写入数据， leader副本
	leader副本接收到数据之后，follower副本会不停的发送请求
	尝试拉取最新的数据，拉取到本地磁盘

4) Isr
	In-Sync Replicas  保持同步的副本 
	跟leader始终保持同步的follower有哪些
	Isr: 0,1,2

5) acks
	0：
		producer只管发送 

	1
		leader ok就ok  不管follower

	all
		IRS里面都ok













